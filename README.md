# stacked-regressor-housing-kaggle
My 3rd competition on kaggle, using Stacked Regressor on housing data.  

Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.

With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.

Includes the following - 
1. Imputing missing values
2. Transforming some numerical variables that seem really categorical
3. Label Encoding
4. Box Cox Transformation of skewed features (instead of log-transformation)
5. Getting dummy variables for categorical features
6. Exploring advanced linear regression techniques like - LASSO Regression, Elastic Net Regression, Kernel Ridge Regression,      Gradient Boosting Regression, XGBoost, LightGBM
7. Simple stacking of regressors - taking average
8. Advanced stacking using meta model 
